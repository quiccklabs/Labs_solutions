{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc61ef2",
   "metadata": {},
   "source": [
    "### Getting Started "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5040b",
   "metadata": {},
   "source": [
    "#### Install Google Gen AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cb94a-444f-4360-9196-395da2f58a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a8346",
   "metadata": {},
   "source": [
    "#### Restart runtime\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aad280-7db1-4e39-886b-336d7e5791d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart the kernel after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f5a9c",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45472ded-bc1f-47a5-9782-fb8fb8538f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-8037e12a9026\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Create the API client\n",
    "from google import genai\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d907146",
   "metadata": {},
   "source": [
    "#### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c672ce5-01ee-4884-a76f-c069d06c412a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    Tool,\n",
    "    Part\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901e8a",
   "metadata": {},
   "source": [
    "### Task 3. Create a function call using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e9207-2646-4378-9350-cef083822807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.1\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "# Load Gemini 2.0 Flash 001 Model\n",
    "model_id = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d349748-4a56-4759-98d7-e918b476c317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.2\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aa0f9-ef27-4664-b9f6-ed6847d8f76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.3\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "weather_tool = Tool(\n",
    "    function_declarations=[get_current_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b41dfd-5d43-4c21-8992-c76ed319af66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.4\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "prompt = \"What is the weather like in Boston?\"\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[weather_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de586d1d",
   "metadata": {},
   "source": [
    "### Task 4. Describe video contents using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8033df-507a-4fc8-b14c-f015be9f66af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the following cell to import required libraries \n",
    "from google.genai.types import (\n",
    "    GenerationConfig,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75434b8d-e7d0-4241-9cab-fa735a617b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 4.1\n",
    "# Load the correct Gemini model use the following documentation to assist:\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview#supported-use-cases\n",
    "# Load Gemini 2.0 Flash 001 Model\n",
    "multimodal_model = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6f262-1956-4c3e-a0ab-39b412d19ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980efdfb-bd68-4795-8713-89b8422cd0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "What is shown in this video?\n",
    "Where should I go to see it?\n",
    "What are the top 5 places in the world that look like this?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    file_uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = client.models.generate_content_stream(\n",
    "    model=multimodal_model,\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde0bb0-f1a4-474b-b3d7-208d0bafc6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
