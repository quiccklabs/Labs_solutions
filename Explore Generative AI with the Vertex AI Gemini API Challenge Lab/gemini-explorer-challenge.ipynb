{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974ac24-0b81-43eb-a8b3-5bc86d402552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required python packages\n",
    "!pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92d0b4-d250-4a29-ae4b-5f296f14e896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart the kernet after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4c364-eba0-4c62-85b7-f7c2c25b1e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# import software libraries required\n",
    "import requests\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d402d35-2356-47d5-973d-b69c106087f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.1\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcef55b-2fd3-4357-b62d-c8a48d388f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.2\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcf2f0-1b02-49c3-abf1-646403ca47d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.3\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "weather_tool = Tool(\n",
    "    function_declarations=[get_current_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd435f-43e9-4775-902c-42575bd2f61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.4\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "prompt = \"What is the weather like in Boston?\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config={\"temperature\": 0},\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627baf8-cccb-467f-8ebe-cc4b3906ff33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Run the following cell to import required libraries \n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d306edd-9888-4346-beab-120009fdb630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.1\n",
    "# Load the correct Gemini model use the following documentation to assist:\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview#supported-use-cases\n",
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed775b0-d63a-4a6a-9a55-8fe85ba0304b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e0a91-d216-4a48-a7de-587cb9d6782e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.2 Generate a video description\n",
    "# In this cell, update the prompt to ask Gemini to describe the video URL referenced.\n",
    "# You can use the documentation at the following link to assist.\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference#generate-content-from-video\n",
    "# \n",
    "# Video URI: gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\n",
    "# \n",
    "prompt = \"\"\"\n",
    "What is shown in this video?\n",
    "Where should I go to see it?\n",
    "What are the top 5 places in the world that look like this?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content (contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb8b02-3cb9-4623-8e2b-3c7079d160c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2ad36-05a8-4843-b041-accbafc751c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-15.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-15:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
